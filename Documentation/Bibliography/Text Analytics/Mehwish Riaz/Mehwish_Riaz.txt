defining Causaulity
-------------------
Manipulation Theory of Causality:
	determines truth of the following two conditions 
	(1) event a must temporally precede or overlap event b in time and (2) while keeping as many state of current affairs constant as possible, modifying event a must entail predictably modifying event b
-----------------------------------------------------


two verbs can appear in any context i.e, explicit and unambiguous, ambiguous or implicit context

the association of figurative (non-literal) readings with natural language expressions (e.g., nouns) can complicate the task of identifying causality.
e.g The United States has killed Osama bin Laden and has custody of his body.
the noun phrase "The United States" refers to an event of "raid in Abbottabad on May 2, 2011" rather than merely referring to the country.


----
Goal
----
take advantage of explicit and unambiguous discourse markers to automatically acquire a training corpus for the current task. Using this training corpus, we build a supervised classifier for verb-verb pairs employing the linguistic features introduced in Bethard and Martin (2008) and some features we introduce in this work. Moreover, in order to perform well on all types of context, we propose to incorporate additional sources of knowledge such as background knowledge on top of the supervised classifier for verb-verb pairs.
-----------------------------------------------------


humans also make use of other information such as background knowledge to comprehend causality. The complexity of the task of detecting causality stems from the fact that there are many factors involved, such as linguistic features of an instance, background knowledge, semantic and pragmatic features of events, world knowledge, etc.

we propose a method which employs the annotations of FrameNet corpus [Baker et al. 1998] for noun phrases to identify tendencies of nouns to encode a cause or non-cause relation. This information is then used in our model to reduce noise in the predictions of a supervised classifier for the verb-noun pairs

acquire the following four types of knowledge for the current tasks: (1) Background Knowledge, (2) Causal Semantics of Verbs, (3) Causal Semantics of Nouns and (4) Causal Semantics of Verb Frames.


--------------
Knowledge Base
--------------
We exploit the information available from a large number of unlabeled instances of verb-verb pairs to mine causal associations in these pairs.

We store the information regarding causal associations of verb-verb pairs in a resource named the knowledge base of causal associations (KBc). In this resource, we keep the scores of likelihood of each verb-verb pair to encode causation. Depending on the likelihood of causality in verb-verb pairs, we create three categories of these pairs: Strongly Causal, Ambiguous and Strongly Non-causal.

For example, the pair (kill, arrest) has a high tendency to encode causation irrespective of the context of an instance in which it is used, thereby a good indicator of causality.

The resource KBc introduced above provides a rich source of background knowledge for
identifying causality in verb-verb pairs
-----------------------------------------------------


-------------------------
Causal Semantics of Verbs
-------------------------
STATE describes an unchanging situation over a period of time (e.g., know, love) and an EVENT describes a situation which involves internal structure (e.g., run has an internal structure of raising a foot in air, moving it forward and putting it down on floor)

we identify if both verbs of an instance of verb-verb pair represent events or not and provide this
information to our model for identifying causality. 

In addition to the above, we also incorporate the semantic classes of events to learn the causal semantics of verbs.

for the TimeBank's corpus, Pustejovsky et al., (2003) have categorized the instances of verbal events into seven semantic classes { i.e., OCCURRENCE, PERCEPTION, ASPECTUAL, STATE, I STATE, I ACTION and REPORTING. Based on the definitions of these classes [Pustejovsky et al. 2003], we argue that each verb can have its own causal semantics depending on the class of event it represents.

we propose a data intensive method to identify tendencies of each of the above stated semantic classes and provide this information to our model for identifying causality. We acquire and employ the knowledge of causal semantics of verbs for identifying causality in verb-verb and verb-noun pairs
-----------------------------------------------------


-------------------------
Causal Semantics of Nouns
-------------------------
we propose a method which automatically acquires the semantic classes of nouns with a high and low tendency to encode causal relations.
-----------------------------------------------------


-------------------------------
Causal Semantics of Verb Frames
-------------------------------

10. The Great Storm of October 1987 almost totally destroyed the eighty year old pinetum at Nymans Garden in Sussex.
11. The explosion occurred in the city's main business area.

The above two examples show that the verbs "destroy" and "occur" have their own tendencies to encode causation with their subjects. Particularly, in above examples the verb frames of form {destroy, subject} and {occur, subject} encode a cause and non-cause relation, respectively. 

In this work, we leverage the annotations of verbs in FrameNet [Baker et al. 1998] to identify tendencies of verb frames to encode causation. In addition to above, we also determine the likelihood of a subject (or any grammatical relation) of any verb to encode causation with its verb.
-----------------------------------------------------

------------
Verbal Event
------------
A verbal event (denoted by evi ) is defined as a 3-tuple ([subjectvi ] , vi, [objectvi ]), where vi is the main verb and the rest of the elements of this 3-tuple are core arguments of the verb vi i.e., subject and object. These arguments are not always explicitly available in an instance. We assign a NULL value for a missing argument of the 3-tuple

---------------
Causal Relation
---------------
the causal relations between events are broadly seen as contingency semantic relations (cause-consequence, argument-claim, instrument-goal, purpose and reason/explanation)



===============================
======= VERB-VERB PARIS =======
===============================


--------
Pipeline
-------- 
the component "Identification of Causality via Linguistic Features" is a supervised classifier which identifies causality by exploiting linguistic features. These features are extracted from the contexts of instances of evi-evj pairs. This component provides the labels C or ~C on the instances of evi-evj pairs and the probabilities of assignments of labels. 

We use the term "knowledge of context" for the probabilities of assignments of labels. The above supervised classifier serves as a baseline for our model. 

On top of the knowledge of context, we plug in background knowledge from the component "Extraction of Background Knowledge" and the knowledge of causal semantics of verbs from the component "Identification of the Causal Semantics of Verbs". 

In order to integrate the above stated types of knowledge, we employ the learning and inference framework of Integer Linear Programming (ILP) for NLP


------------------------------
Acquisition of Training Corpus
------------------------------
* Section 3.1.1

we propose a method to leverage unambiguous discourse markers to acquire a training corpus for building a supervised classifier

Causal 
	because, for this (that) reason, consequently, as a consequence of, as a result of

Non-causal 
	but, in short, in other words, whereas, on the other hand, nevertheless, nonetheless, in spite of, in contrast, however, even, though, despite the fact, conversely, although.


In order to extract the non-causal event- event pairs, we utilize the instances of two discourse segments conjoined by non-causal markers (e.g., "but" which represents comparison (non-causal) relation). Any event-event pair collected from the two discourse segments in non-causal relation encodes non-causality. Therefore, we select the closest verb-verb pair from the instances of the form I with a non-causal marker conjoining the two discourse segments.

In this research, we also employ the manually annotated training corpus Penn Discourse Tree Bank (PDTB) for our purpose [Prasad et al. 2008]. This corpus provides labels for contingency (causal) and non- contingency (non-causal) relations on the pairs of discourse segments (also known as Elementary Discourse Units (EDU)). For our task, we apply the above stated method to automatically acquire the training instances of evi -evj pairs from the instances of EDU-EDU pairs of the PDTB corpus.




Table 3.2

--------------------
Background Knowledge
--------------------
causal associations of verb-verb pairs.
likelihood of verb-verb pairs to encode cause or non-cause relation
In order to acquire causal associations of verb-verb pairs, we extract a set of large number of unlabeled intra- and inter-sentential instances of these pairs. This set is referred to as the development set of our model. 

We collect instances of verb-verb pairs from the same sentences (intra-sentential) and adjacent sentences (inter-sentential) of the documents as follows. 
	We remove stopwords and retain only main verbs in the sentences. 
	For each sentence, we collect all pairs of main verbs (i.e., (vi-vj)) to generate the intra-sentential instances of verb-verb pairs. 
	For each of two adjacent sentences sl and sm of a document, we collect all pairs of main verbs i.e., vi-vj where vi (vj) appears in sl (sm), respectively. This results in generation of the inter-sentential instances of verb-verb pairs. 
	We use these intra- and inter-sentential instances to derive the causal associations of verb-verb pairs. 
	To determine causal associations with confidence, we retain only those verb-verb pairs which have at least 30 instances in the development set. 
	Also, we consider only those intra-sentential instances of verb-verb pairs in which two verbs are separated by at least two words.


---------------------------------
Explicit Causal Association (ICA)
---------------------------------
In order to find the likelihood of a verb-verb pair to encode causal relations, we introduce a novel metric, Explicit Causal Association (ECA).

* Section 3.2.1

Following are some examples of causal verb-verb pairs from these top 500 pairs: 
	destroy-rebuild, convict-arrest, receive-download, ask-reply, score-win, etc. 

We also observed some false positives in the top 500 pairs i.e., those pairs which do not seem to encode a cause-effect relation. Some examples of these pairs are 
	jump-rise, hit-strike, drop-fall, climb-gain, meet-discuss, etc. 

Notice that in these examples some pairs contain nearly synonymous verbs 
	(e.g., jump-rise, hit-strike) 
or the verbs in temporal only relation 
	(e.g., drop-fall, climb-gain, meet-discuss).

 
We use the term training data sparseness for this problem where the strongly causal verb-verb pairs hardly appear in the Explicit evi-evj training corpus. Due to this problem, we can mistakenly consider the strongly causal verb-verb pairs as non-causal. 


---------------------------------
Implicit Causal Association (ICA)
---------------------------------
we propose a metric ICA to handle the problem of training data sparseness

* Section 3.2.2

This metric makes use of functions for the identification of roles of events in a cause relation.

Each of the two events in a causal relation can be assigned either cause or effect role.

We use core features of events to determine the likelihood of their roles in causation. These features include lemmas, part-of-speech tags, all senses from WordNet of both verbs and their arguments (i.e., subject and object). Next, we use these features to handle training data sparseness.

Because 					(ev_before , rE), (ev_after , rC)
For this (that) reason 		(ev_before , rC), (ev_after , rE)
Consequently 				(ev_before , rC), (ev_after , rE)
As a consequence of 		(ev_before , rE), (ev_after , rC)
As a result of 				(ev_before , rE), (ev_after , rC)

We acquire the likelihood of each verb-verb pair to encode causation via above metrics and store this information in a resource called the knowledge base of causal associations of verb-verb pairs (i.e., KBc).

-----------------------------
Forms of Background Knowledge
-----------------------------
We derive these two forms using the scores of likelihood of verb-verb pairs to encode causation. These scores of likelihood of causality in verb-verb pairs are available from the above stated resource KBc.

Ranking Scores of verb-verb pairs
	we assign a ranking score to each vi-vj pair based on its likelihood to encode causation as compared with other verb-verb pairs of the language.

	We use the notation KB1 for this form of background knowledge.

Categories of verb-verb pairs
	we divide verb-verb pairs into three categories: (1) Strongly Causal (Sc), (2) Ambiguous (Ac) and (3) Strongly Non-causal (S:c) to provide background knowledge.

	We use the notation KB2 for this form of background knowledge.


------------------------------
Linguistic Defintion of Events
------------------------------
STATE describes an unchanging situation over a period of time (e.g., know, love) and an EVENT describes a situation which involves internal structure (e.g., run has an internal structure of raising a foot in air, moving it forward and putting it down on floor)

for a pair vi-vj, we first automatically identify if any of the two 3-tuples (i.e., evi or evj ) represents an event according to the linguistic definition or not

the pair evi-evj can encode causation only if at least one of evi and evj is an event according to the linguistic definition.

Inspired by the work of Bethard and Martin (2006), we build a supervised classifier to predict the labels E or ~E on both of the 3-tuples of evi-evj pairs. 

We employ the TimeBank's annotations of verbal events and non-events and the features given in Table 3.4 to build the supervised classifier. After acquiring the labels from this classifier, a pair evi-evj can fall into one of the following four cases:
	event-event
	event-not_event
	not_event-event
	not_event-not_event


--------------------------
Semantic Classes of Events
--------------------------
Procedure 3.1 given below takes a training corpus of evi -evj pairs with C and :C labels and a set of se- mantic classes - i.e., SC={OCCURRENCE, PERCEPTION, ASPECTUAL, STATE, I STATE, I ACTION, REPORTING} as input. This procedure outputs a set SC_~c which contains the semantic classes with the highest tendency to encode non-cause relations.



-------------------------
Integer Linear Programing
-------------------------

In the framework of Integer Linear Programming for NLP [Roth and Yih 2004], various sources of knowledge are added in the form of hard and soft constraints to an integer linear program

In our approach, we begin with setting up an integer linear program with the knowledge of context and then incrementally add other types of knowledge to achieve progress over the model relying merely on linguistic features


===============================
======= VERB-NOUN PAIRS =======
===============================

For an instance of v-np pair, the verb (v) can represent either a cause event or an effect event and the same is the case with noun phrase (np). 

In addition to this, the v and np can appear anywhere in the sentence and in any order. We consider only relations between the main verbs and the noun phrases for the current task.


--------
Pipeline
-------- 

In our model, the component "Identification of Causality via Linguistic Features" is a supervised classifier which identifies causality by exploiting linguistic features.

This component assigns the labels C or :C on the instances of v-np pairs and provides the probabilities of these assignments.

After the acquisition of knowledge of context, the components "Identification of the Causal Semantics of Nouns", "Identification of the Causal Semantics of Verbs" and "Identification of the Causal Semantics of Verb Frames" identify the knowledge of causal semantics of nouns, verbs and verb frames. 

We also introduce a component "Identification of Indistinct Verbs and Nouns" for extracting the knowledge of indistinct verbs and nouns {i.e., the knowledge of verbs and nouns which do not represent distinct state of affairs.

In our model we integrate all of the above stated types of knowledge via Integer Linear Programming (ILP) framework for NLP


---------------------------------------------------------
Examples of FrameNet Labels assigned to causal-non-causal
---------------------------------------------------------
C 
	Cause, Purpose, Reason, Explanation, Required situation, Purpose of event, Negative consequences, Resulting action, Internal cause, Result, External cause, Effect, Cause of shine, Purpose of goods, Response action, Enabled situation, Grinding cause, Trigger

~C 
	Place, Speed, Driver, Attribute, Time, Path, Manner, Duration, Means, At- tribute, Activity, Group, Protagonist, Difference, Process, Content, Execu- tioner, Amount


In order to set up a supervised classifier for the current task, we acquire the training corpus of v-np pairs by leveraging the annotations for all verbs in the FrameNet corpus


In our model, we collect all FrameNet's annotations for verbs such that the labeled elements do not contain any verb and must contain at least one noun to represent a relation at the v-np level. If a labeled element contains a verb then this may not encode a relation at the v-np level

729 distinct frame elements of the FrameNet. We manually assigned the labels C and :C to all of these frame elements to generate the training corpus for the current task

----------------------------------
Linguistic Features for Classifier
----------------------------------
* Section 5.1.2

-------------------------
Causal Semantics of Nouns
-------------------------

In order to identify causality in verb-noun phrase pairs, our model needs to have knowledge of causal
semantics of nouns. We identify this type of knowledge in terms of the semantic classes of nouns with a
high and low tendency to encode causation

we identify two classes of noun phrases named as Cnp and ~Cnp where the class Cnp (~Cnp) contains the noun phrases with a high (low) tendency to encode causation, respectively.

FrameNet. We consider only those annotations in which the labeled elements do not contain any verb
and must contain at least one noun. These annotations roughly represent instances of noun phrases. We
manually examined the inventory of frame elements acquired from these annotations and assign these frame
elements to the classes Cnp and ~Cnp.

We use these assignments of frame elements to apply the labels of Cnp and ~Cnp to the annotations of FrameNet corpus. Using the above method, we have acquired 52,706 Cnp and 94,841 ~Cnp instances. We use the term FNETnp to refer to the corpus of these instances.

In addition to above mentioned corpus obtained from FrameNet, we also employed WordNet to extract more training instances of the classes Cnp and ~Cnp. For this purpose, we followed the approach similar to Girju and Moldovan (2002) and adopted some senses of WordNet shown in Table 5.4.

Cnp 
	{act, deed, human action, human activity}, {phenomenon}, {state}, {psychological feature}, {event}, {causal agent, cause, causal agency}
~Cnp 
	{time period, period of time, period}, {measure, quantity, amount}, {group, grouping}, {organization, organisation}, {time unit, unit of time}, {clock time, time}

We employ the term FNET-WNETnp to refer to the training corpus with instances of noun phrases acquired using FrameNet and WordNet

After removing the instances of FNETnp's corpus from the FNET-WNETnp's corpus, we are left with 87,400 Cnp and 45,265 ~Cnp instances of noun phrases. We use the term WNETnp to refer to the training corpus with these instances.



In order to build the supervised classifier, we employ the following list of features:
	* Lexical Features: All words, lemmas of all words of the noun phrase, the head noun of the noun phrase, first two (three) (four) letters of the head noun of the noun phrase, last two, (three) (four) letters of the head noun of the noun phrase.
	* Syntatic Features: part-of-speech tags of all words of the noun phrase and the head noun of the noun phrase.
	* Semantic Features: Frequent sense of the head noun of the noun phrase.We

we also apply a named entity recognizer [Finkel et al. 2005] to identify the seven types of named entities (i.e., LOCATION, PERSON, ORGANIZATION, DATE, TIME, MONEY, PERCENT). On getting an instance of verb-noun phrase, if the noun phrase is identified as a named entity then we assume that it belongs to the class ~Cnp unless a metonymy is associated with it.


----------
Metonymies
----------
A part of the task of metonymy resolution is to determine if a literal or a non-literal (figurative) sense is associated with a natural language expression

We assume that a noun phrase 2 ~Cnp with the metonymic reading associated with it can encode causation as compared with the noun phrase 2 ~Cnp with no metonymic reading.

In our method, we leverage the verb frames and the prepositions acquired from the annotations of FrameNet corpus to identify the association of metonymies with noun phrases.

-----------
Verb Frames
-----------
we learn the rules of language with respect to verb frames and exploit the violations of these rules to identify the association of non-literal sense with the noun phrases.

In order to learn the rules of language with respect to verb frames, we extract all the annotations of FrameNet for the verbs in which the labeled elements do not contain any verb in it. We impose this restriction because we predict the association of metonymies with noun phrases. 

We assume that a labeled element with no verb in it roughly represents a noun phrase expression1. We use the assignments of frame elements to the classes Cnp and ~Cnp discussed in section 5.2.1 to learn the rules of language.

In FrameNet, annotations are provided using the actual semantic sense of language expressions rather than literal sense.

This knowledge base contains the fields of Verb (V), Grammatical Relation (GR), CountCnp and Count~Cnp . The grammatical relation is the dependency relation [Marneffe et al. 2006] of a labeled element with respect to a verb.

------------
Prepositions
------------

In the second part of our method, we identify the tendencies of prepositions to encode causal relations and use the violation of these tendencies to identify metonymies.

* Section 5.2.2 (page 95)

-----------------------------------------------
Identification of the Causal Semantics of Verbs
-----------------------------------------------
Using the supervised classifier introduced in section 3.3.2, we identify the semantic classes of events represented by the verbs of v-np pairs of FNETv-np corpus.

For the current task, we have derived the following classes Cev={OCCURRENCE, PER- CEPTION, ASPECTUAL, STATE, I ACTION} and ~Cev= {REPORTING, I STATE} using the FNETv-np corpus where the class Cev (~Cev) contains the semantic classes of events with a high (low) tendency to encode causation, respectively.


-----------------------------------------------------
Identification of the Causal Semantics of Verb Frames
-----------------------------------------------------
In order to identify causality in verb-noun phrase pairs, we assume that it is important for a model to have information of the verb frames which support encoding of causality.

we propose our method to identify tendencies of the verb frames of form fv, grg to encode causation. In the verb frame {v, gr} v is the verb and gr is the grammatical relation with the verb v

We leverage all the annotations of FrameNet for verbs to acquire the above type of knowledge. After acquiring these annotations, we apply the labels C and ~C to the frame elements as introduced in the section 5.1.1.

* Section 5.4

--------------------------------------------
Identification of Indistinct Verbs and Nouns
--------------------------------------------

Each causal relation is characterized by two roles i.e., cause and its effect. In example (1), the noun "hurricane" is cause and the verb "died" is its effect. However, a verb-noun phrase pair may not encode causality when a verb and a noun phrase represent the same state of affairs.

e.g 22. Colin Powell presented further evidence in his presentation.
Here the verb "presented" and the noun phrase "presentation" represent same event of "presenting" and thus encode a non-cause relation with each other.

* Section 5.5




